name: Multi-State Environmental Scraper

on:
  schedule:
    # Runs at 3 AM EST daily
    - cron: '0 8 * * *'
  workflow_dispatch:

jobs:
  scrape-violations:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        pip install requests pandas beautifulsoup4
        pip install lxml openpyxl
    
    # - name: Run EPA ECHO scraper
    #   run: python epa_echo_scraper.py
      
    - name: Run state scrapers
      run: python multi_state_scraper.py
    
    - name: Combine and deduplicate data
      run: |
        python - <<EOF
        import pandas as pd
        import glob
        from datetime import datetime
        
        # Find all today's CSV files
        today = datetime.now().strftime("%Y%m%d")
        files = glob.glob(f"scraped_data/*_{today}*.csv")
        
        # Combine by state - removed WV
        for state in ["VA", "PA", "MD"]:
            state_files = [f for f in files if f"/{state}_" in f or f"/ECHO_{state}" in f]
            if state_files:
                dfs = [pd.read_csv(f) for f in state_files]
                combined = pd.concat(dfs, ignore_index=True)
                combined.drop_duplicates(inplace=True)
                combined.to_csv(f"scraped_data/{state}_combined_{today}.csv", index=False)
                print(f"Combined {len(state_files)} files for {state}: {len(combined)} total records")
        
        # Also create combined file for WV from ECHO only
        wv_files = [f for f in files if "/ECHO_WV" in f]
        if wv_files:
            dfs = [pd.read_csv(f) for f in wv_files]
            combined = pd.concat(dfs, ignore_index=True)
            combined.drop_duplicates(inplace=True)
            combined.to_csv(f"scraped_data/WV_combined_{today}.csv", index=False)
            print(f"Combined {len(wv_files)} ECHO files for WV: {len(combined)} total records")
        EOF
    
    - name: Generate summary report
      run: |
        python - <<EOF
        import pandas as pd
        import glob
        from datetime import datetime
        
        today = datetime.now().strftime("%Y%m%d")
        summary = []
        
        for state in ["VA", "PA", "MD", "WV"]:
            try:
                df = pd.read_csv(f"scraped_data/{state}_combined_{today}.csv")
                summary.append({
                    'State': state,
                    'Total Violations': len(df),
                    'Date': today
                })
            except:
                pass
                
        if summary:
            summary_df = pd.DataFrame(summary)
            summary_df.to_csv(f"scraped_data/daily_summary_{today}.csv", index=False)
            print(summary_df.to_string())
        EOF
    
    - name: Commit and push
      run: |
        git config --global user.email "github-actions[bot]@users.noreply.github.com"
        git config --global user.name "github-actions[bot]"
        git add scraped_data/*.csv
        if git diff --staged --quiet; then
          echo "No changes to commit"
        else
          git commit -m "Auto-update: Multi-state violations $(date +'%Y-%m-%d')"
          git pull --rebase origin main
          git push
        fi
